{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ericuX_zTMmu"
      },
      "outputs": [],
      "source": [
        "# Copyright (c) Innoptech"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP7Z5v82SqKM"
      },
      "source": [
        "# **OpenFDCM: Fast Template Matching for Object Pose Estimation**\n",
        "\n",
        "### **Overview**\n",
        "**OpenFDCM** (Fast Directional Chamfer Matching) is a high-performance, production-ready, fast template matching library designed to **enable object pose estimation**, particularly in industrial and manufacturing environments. This library excels at matching templates while remaining invariant to **translation** and **rotation** in the image plane.\n",
        "\n",
        "The library is very extensible. One could easily implement a CUDA module for example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEANPaPYq1bx"
      },
      "source": [
        "This Jupyter notebook focuses solely on documenting the fast template matching algorithms provided by OpenFDCM. For complete 6-DOF pose estimation, please refer to the repository's [README.md](https://github.com/Innoptech/OpenFDCM/blob/main/README.md). It is important to note that the output of OpenFDCM generates a comprehensive list of match candidates, which should be refined using the multiview techniques discussed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz-qbxAxU87F"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/drive/1AtXjSrxsd42BVli3xbOR2b8pRkfyrb0m?usp=sharing\">\n",
        "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg-eqlAScYdS"
      },
      "source": [
        "\n",
        "### Environment Set-up\n",
        "\n",
        "* If running locally using jupyter, first install `openfdcm==0.8.2` in your environment using the installation instructions in the repository.\n",
        "\n",
        "* If running from Google Colab, set using_colab=True below and run the cell.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yvNJf9AldYcf"
      },
      "outputs": [],
      "source": [
        "using_colab = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rm79DPTYSnVO",
        "outputId": "c8d18122-1642-4da1-f393-a3c2de2fafb0"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "if using_colab:\n",
        "  import sys\n",
        "  !{sys.executable} -m pip install openfdcm==0.8.2 \n",
        "  !{sys.executable} -m pip install numpy==2.1.0 opencv-python-headless==4.10.0.84\n",
        "  !git clone --branch v0.8.2 --single-branch --depth 1 https://github.com/Innoptech/OpenFDCM ./OpenFDCM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRRooNI7XBHd"
      },
      "source": [
        "### Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Weudi63Cd7eE",
        "outputId": "c1d77e8a-3f3e-4356-f904-ff1d99499614"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import openfdcm\n",
        "print(\"OpenFDCM version:\", openfdcm.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "KGKOy8-LW_fJ"
      },
      "outputs": [],
      "source": [
        "def apply_transform(template: np.ndarray, transform: np.ndarray):\n",
        "    num_lines = template.shape[1]\n",
        "    transformed_template = np.zeros_like(template)\n",
        "    for i in range(num_lines):\n",
        "        point1 = np.dot(transform[:2, :2], template[:2, i]) + transform[:2, 2]\n",
        "        point2 = np.dot(transform[:2, :2], template[2:, i]) + transform[:2, 2]\n",
        "        transformed_template[:2, i] = point1\n",
        "        transformed_template[2:, i] = point2\n",
        "    return transformed_template\n",
        "\n",
        "def draw_lines(image: np.ndarray, lines: np.ndarray):\n",
        "    for i in range(lines.shape[1]):\n",
        "        pt1 = (int(lines[0, i]), int(lines[1, i]))\n",
        "        pt2 = (int(lines[2, i]), int(lines[3, i]))\n",
        "        cv2.line(image, pt1, pt2, (255, 0, 0), 2)\n",
        "    return image\n",
        "\n",
        "def display_best_match(scene_image: np.ndarray, best_matches: list[openfdcm.Match], templates: list[np.ndarray]):\n",
        "    for match in best_matches:\n",
        "        best_match_template = templates[match.tmpl_idx]\n",
        "        transformed_template = apply_transform(best_match_template, match.transform)\n",
        "        result_image = draw_lines(scene_image, transformed_template)\n",
        "    result_image_rgb = cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(result_image_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def find_files_recursive(directory, extension):\n",
        "    return list(Path(directory).rglob(f\"*{extension}\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_ykbvfVf7Bp"
      },
      "source": [
        "### Templates sampling\n",
        "The template sampling consists in a fast OpenGL sythetic-rendered multiflash depth edge extraction. Further details can be seen in my master thesis (Ref to come).\n",
        "<p float=\"left\">\n",
        "  <img src=\"https://raw.githubusercontent.com/Innoptech/OpenFDCM/v0.8.1/docs/static/templates_sampling.png\" alt=\"Templates Sampling\" width=\"45%\" />\n",
        "  <img src=\"https://raw.githubusercontent.com/Innoptech/OpenFDCM/v0.8.1/docs/static/multiflash_sampling.png\" alt=\"Multiflash Sampling\" width=\"45%\" />\n",
        "</p>\n",
        "\n",
        "For the sake of simplification, the templates have already been generated in this example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXA0Q0sRywyb"
      },
      "source": [
        "### Template matching\n",
        "**Please note that Google Colab CPUs are quite slow.**  \n",
        "**Also note that the shown matches should be refined using the multiview techniques discussed.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caD6EIBOy6K_",
        "outputId": "18386310-dfc8-4996-b455-af3b5a395bb0"
      },
      "outputs": [],
      "source": [
        "from psutil import *\n",
        "# This line will return the CPU info\n",
        "!cat /proc/cpuinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "92OBUa4pgUX3",
        "outputId": "0c77e229-8b45-448f-c929-0702aa604cfc"
      },
      "outputs": [],
      "source": [
        "for imagepth in find_files_recursive(\"./OpenFDCM/notebooks/assets\", \".jpg\"):\n",
        "    scene_dir: Path = imagepth.parent\n",
        "    obj_dir: Path = scene_dir.parent\n",
        "    templates_dir: Path = scene_dir.parent / \"templates\"\n",
        "\n",
        "    scene_image = cv2.imread(str(imagepth))\n",
        "    scene = openfdcm.read(str(scene_dir/\"camera_0.scene\"))\n",
        "\n",
        "    templates = []\n",
        "    for tmpl_path in find_files_recursive(templates_dir, \".tmpl\"):\n",
        "        templates.append(openfdcm.read(str(tmpl_path)))\n",
        "\n",
        "    # Perform template matching\n",
        "    max_tmpl_lines, max_scene_lines = 4, 10  # Combinatory search parameters (the higer the better but exp slower).\n",
        "    depth = 30              # The [0, pi] discretization, the higher, the most precise but lin slower.\n",
        "    scene_padding = 1.0     # A ratio to pad the scene images used in the FDCM algorithm, use if best match may appear on image boundaries.\n",
        "    coeff = 5.0             # A weighting factor to enhance the angular cost vs distance cost in FDCM algorithm.\n",
        "    #num_threads = 4\n",
        "\n",
        "    threadpool = openfdcm.ThreadPool() # could pass num_threads here, but default is optimal\n",
        "    featuremap_params = openfdcm.Dt3CpuParameters(depth, coeff, scene_padding)\n",
        "    search_strategy = openfdcm.DefaultSearch(max_tmpl_lines, max_scene_lines)\n",
        "    optimizer_strategy = openfdcm.BatchOptimize(10, threadpool)\n",
        "    matcher = openfdcm.DefaultMatch()\n",
        "    # Penalize each match with 1/n^tau where n is the number of line in the template\n",
        "    penalizer = openfdcm.ExponentialPenalty(tau=1.5)\n",
        "\n",
        "    # Build FDCm feature map and search\n",
        "    start_time = time.time()\n",
        "    featuremap = openfdcm.build_cpu_featuremap(scene, featuremap_params, threadpool)\n",
        "    raw_matches = openfdcm.search(matcher, search_strategy, optimizer_strategy, featuremap, templates, scene)\n",
        "    penalized_matches = openfdcm.penalize(penalizer, raw_matches, openfdcm.get_template_lengths(templates))\n",
        "    sorted_matches = openfdcm.sort_matches(penalized_matches)\n",
        "    search_time = time.time() - start_time\n",
        "\n",
        "    if sorted_matches:\n",
        "        best_matches = sorted_matches[:10]\n",
        "        display_best_match(scene_image, best_matches, templates)\n",
        "    print(f\"Template matching search completed in {search_time:.4f} seconds (see image above for unrefined 10 best matches).\")\n",
        "    print(\"Expected performance: Should run at 22 FPS (0.045ms) on an i7-14700 CPU with max_tmpl_lines = 4, max_scene_lines = 10, depth = 30.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
