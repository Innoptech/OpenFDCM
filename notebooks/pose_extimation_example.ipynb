{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Innoptech"
      ],
      "metadata": {
        "id": "ericuX_zTMmu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **OpenFDCM: Fast Template Matching for Object Pose Estimation**\n",
        "\n",
        "### **Overview**\n",
        "**OpenFDCM** (Fast Directional Chamfer Matching) is a high-performance, production-ready, fast template matching library designed to **enable object pose estimation**, particularly in industrial and manufacturing environments. This library excels at matching templates while remaining invariant to **translation** and **rotation** in the image plane.\n",
        "\n",
        "The library is very extensible. One could easily implement a CUDA module for example."
      ],
      "metadata": {
        "id": "qP7Z5v82SqKM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Jupyter notebook focuses solely on documenting the fast template matching algorithms provided by OpenFDCM. For complete 6-DOF pose estimation, please refer to the repository's [README.md](https://github.com/Innoptech/OpenFDCM/blob/main/README.md). It is important to note that the output of OpenFDCM generates a comprehensive list of match candidates, which should be refined using the multiview techniques discussed."
      ],
      "metadata": {
        "id": "SEANPaPYq1bx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/drive/1AtXjSrxsd42BVli3xbOR2b8pRkfyrb0m?usp=sharing\">\n",
        "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\">\n",
        "</a>"
      ],
      "metadata": {
        "id": "Xz-qbxAxU87F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Environment Set-up\n",
        "\n",
        "* If running locally using jupyter, first install `openfdcm==0.8.1` in your environment using the installation instructions in the repository.\n",
        "\n",
        "* If running from Google Colab, set using_colab=True below and run the cell.\n",
        "\n"
      ],
      "metadata": {
        "id": "dg-eqlAScYdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "using_colab = True"
      ],
      "metadata": {
        "id": "yvNJf9AldYcf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rm79DPTYSnVO",
        "outputId": "01bbbd2a-cf95-4e9a-e01f-7200a2b3d9c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openfdcm==0.8.3\n",
            "  Downloading openfdcm-0.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
            "Downloading openfdcm-0.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (584 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.6/584.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openfdcm\n",
            "Successfully installed openfdcm-0.8.3\n",
            "Cloning into 'OpenFDCM'...\n",
            "warning: redirecting to https://github.com/Innoptech/OpenFDCM/\n",
            "remote: Enumerating objects: 675, done.\u001b[K\n",
            "remote: Counting objects: 100% (675/675), done.\u001b[K\n",
            "remote: Compressing objects: 100% (645/645), done.\u001b[K\n",
            "remote: Total 675 (delta 27), reused 628 (delta 9), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (675/675), 5.16 MiB | 13.69 MiB/s, done.\n",
            "Resolving deltas: 100% (27/27), done.\n",
            "Note: switching to 'e5c7088d88af15fe800bc0ec1b109ab831d67d18'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "if using_colab:\n",
        "  import sys\n",
        "  !{sys.executable} -m pip install openfdcm==0.8.3\n",
        "  !git clone --branch v0.8.3 --single-branch --depth 1 https://github.com/Innoptech/OpenFDCM\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set-up"
      ],
      "metadata": {
        "id": "BRRooNI7XBHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import openfdcm\n",
        "print(\"OpenFDCM version:\", openfdcm.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Weudi63Cd7eE",
        "outputId": "83eec324-c3bd-4d9d-b111-87840e773f5d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenFDCM version: 0.8.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_transform(template: np.ndarray, transform: np.ndarray):\n",
        "    num_lines = template.shape[1]\n",
        "    transformed_template = np.zeros_like(template)\n",
        "    for i in range(num_lines):\n",
        "        point1 = np.dot(transform[:2, :2], template[:2, i]) + transform[:2, 2]\n",
        "        point2 = np.dot(transform[:2, :2], template[2:, i]) + transform[:2, 2]\n",
        "        transformed_template[:2, i] = point1\n",
        "        transformed_template[2:, i] = point2\n",
        "    return transformed_template\n",
        "\n",
        "def draw_lines(image: np.ndarray, lines: np.ndarray):\n",
        "    for i in range(lines.shape[1]):\n",
        "        pt1 = (int(lines[0, i]), int(lines[1, i]))\n",
        "        pt2 = (int(lines[2, i]), int(lines[3, i]))\n",
        "        cv2.line(image, pt1, pt2, (255, 0, 0), 1)\n",
        "    return image\n",
        "\n",
        "def display_best_match(scene_image: np.ndarray, best_matches: list[openfdcm.Match], templates: list[np.ndarray]):\n",
        "    for match in best_matches:\n",
        "        best_match_template = templates[match.tmpl_idx]\n",
        "        transformed_template = apply_transform(best_match_template, match.transform)\n",
        "        result_image = draw_lines(scene_image, transformed_template)\n",
        "    result_image_rgb = cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(result_image_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def find_files_recursive(directory, extension):\n",
        "    return list(Path(directory).rglob(f\"*{extension}\"))"
      ],
      "metadata": {
        "id": "KGKOy8-LW_fJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Templates sampling\n",
        "The template sampling consists in a fast OpenGL sythetic-rendered multiflash depth edge extraction. Further details can be seen in my master thesis (Ref to come).\n",
        "<p float=\"left\">\n",
        "  <img src=\"https://raw.githubusercontent.com/Innoptech/OpenFDCM/v0.8.1/notebooks/images/templates_sampling.png\" alt=\"Templates Sampling\" width=\"45%\" />\n",
        "  <img src=\"https://raw.githubusercontent.com/Innoptech/OpenFDCM/v0.8.1/notebooks/images/multiflash_sampling.png\" alt=\"Multiflash Sampling\" width=\"45%\" />\n",
        "</p>\n",
        "\n",
        "For the sake of simplification, the templates have already been generated in this example."
      ],
      "metadata": {
        "id": "Z_ykbvfVf7Bp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Template matching\n",
        "**Please note that Google Colab CPUs are quite slow.**  \n",
        "**Also note that the shown matches should be refined using the multiview techniques discussed.**"
      ],
      "metadata": {
        "id": "UXA0Q0sRywyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import *\n",
        "# This line will return the CPU info\n",
        "!cat /proc/cpuinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caD6EIBOy6K_",
        "outputId": "57df827c-410b-40cf-ead5-4d100d690e4e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed bhi\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed bhi\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for imagepth in find_files_recursive(\"./OpenFDCM/examples/assets\", \".jpg\"):\n",
        "    scene_dir: Path = imagepth.parent\n",
        "    obj_dir: Path = scene_dir.parent\n",
        "    templates_dir: Path = scene_dir.parent / \"templates\"\n",
        "\n",
        "    scene_image = cv2.imread(str(imagepth))\n",
        "    scene = openfdcm.read(str(scene_dir/\"camera_0.scene\"))\n",
        "\n",
        "    templates = []\n",
        "    for tmpl_path in find_files_recursive(templates_dir, \".tmpl\"):\n",
        "        templates.append(openfdcm.read(str(tmpl_path)))\n",
        "\n",
        "    # Perform template matching\n",
        "    max_tmpl_lines, max_scene_lines = 4, 10  # Combinatory search parameters (the higer the better but exp slower).\n",
        "    depth = 30              # The [0, pi] discretization, the higher, the most precise but lin slower.\n",
        "    scene_padding = 1.0     # A ratio to pad the scene images used in the FDCM algorithm, use if best match may appear on image boundaries.\n",
        "    coeff = 5.0             # A weighting factor to enhance the angular cost vs distance cost in FDCM algorithm.\n",
        "    #num_threads = 4\n",
        "\n",
        "    threadpool = openfdcm.ThreadPool() # could pass num_threads here, but default is optimal\n",
        "    featuremap_params = openfdcm.Dt3CpuParameters(depth, coeff, scene_padding)\n",
        "    search_strategy = openfdcm.DefaultSearch(max_tmpl_lines, max_scene_lines)\n",
        "    optimizer_strategy = openfdcm.BatchOptimize(10, threadpool)\n",
        "    matcher = openfdcm.DefaultMatch()\n",
        "    penalizer = openfdcm.ExponentialPenalty(tau=1.5)\n",
        "\n",
        "    # Build FDCm feature map and search\n",
        "    start_time = time.time()\n",
        "    featuremap = openfdcm.build_cpu_featuremap(scene, featuremap_params, threadpool)\n",
        "    raw_matches = openfdcm.search(matcher, search_strategy, optimizer_strategy, featuremap, templates, scene)\n",
        "    penalized_matches = openfdcm.penalize(penalizer, raw_matches, openfdcm.get_template_lengths(templates))\n",
        "    sorted_matches = openfdcm.sort_matches(penalized_matches)\n",
        "    search_time = time.time() - start_time\n",
        "    print(f\"Template matching search completed in {search_time:.4f} seconds (see image above for unrefined 10 best matches).\")\n",
        "    print(\"Expected performance: Should run at 22 FPS (0.045ms) on an i7-14700 CPU with max_tmpl_lines = 4, max_scene_lines = 10, depth = 30.\")\n",
        "    print(f\"Number of unfiltered match candidates: {len(sorted_matches)}.\")\n",
        "\n",
        "    if sorted_matches:\n",
        "        best_matches = sorted_matches[:10]\n",
        "        display_best_match(scene_image, best_matches, templates)"
      ],
      "metadata": {
        "id": "92OBUa4pgUX3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}